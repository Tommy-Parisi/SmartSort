import numpy as np
from sklearn.cluster import AgglomerativeClustering
from core.models import EmbeddedFile, ClusteredFile
from core.utils import log_error
from sentence_transformers import SentenceTransformer, util
from collections import defaultdict

class ClusteringAgent:
    def __init__(self, max_clusters=20):
        self.max_clusters = max_clusters
        self.name_embedder = SentenceTransformer("all-MiniLM-L6-v2")  

    def _calculate_n_clusters(self, n_files: int) -> int:
        """Calculate the optimal number of clusters based on the number of files."""
        return min(self.max_clusters, max(2, n_files // 5))

    def cluster(self, embedded_files: list[EmbeddedFile]) -> list[ClusteredFile]:
        valid_files = [f for f in embedded_files if f.status == "embedded" and f.embedding]

        if len(valid_files) < 2:
            log_error("[ClusteringAgent] Not enough embeddings to cluster.")
            return []

        X = np.array([f.embedding for f in valid_files])
        try:
            n_clusters = self._calculate_n_clusters(len(valid_files))
            model = AgglomerativeClustering(
                n_clusters=n_clusters,
                metric='cosine',
                linkage='average'
            )
            labels = model.fit_predict(X)
        except Exception as e:
            log_error(f"[ClusteringAgent] Clustering failed: {e}")
            return []

        clustered = []
        for file, label in zip(valid_files, labels):
            clustered.append(ClusteredFile(
                file_meta=file.file_meta,
                embedding=file.embedding,
                raw_text=file.raw_text,
                cluster_id=int(label),
                status="clustered"
            ))

        return clustered
    
    def merge_similar_clusters(
        self,
        cluster_map: dict[int, list[ClusteredFile]],
        cluster_names: dict[int, str],
        similarity_threshold: float = 0.85
        ) -> dict[int, list[ClusteredFile]]:
        """
         Merge clusters whose folder names are semantically similar based on cosine similarity.

        Args:
            cluster_map: original mapping from cluster_id -> list of ClusteredFile
            cluster_names: cluster_id -> folder name generated by FolderNamingAgent
            similarity_threshold: threshold above which to merge names

        Returns:
            A new cluster map with similar clusters merged under the same ID
        """
        # Get embeddings of folder names
        sorted_ids = sorted(cluster_names.keys())
        folder_names = [cluster_names[i] for i in sorted_ids]
        embeddings = self.name_embedder.encode(folder_names, convert_to_tensor=True)

        # Compute pairwise similarity
        similarity_matrix = util.pytorch_cos_sim(embeddings, embeddings).cpu().numpy()

        # Build merge groups using union-find
        parent = {i: i for i in range(len(sorted_ids))}

        def find(i):
            while parent[i] != i:
                parent[i] = parent[parent[i]]
                i = parent[i]
            return i

        def union(i, j):
            pi, pj = find(i), find(j)
            if pi != pj:
                parent[pj] = pi

        for i in range(len(sorted_ids)):
            for j in range(i + 1, len(sorted_ids)):
                if similarity_matrix[i][j] >= similarity_threshold:
                    union(i, j)

        # Map group ID to merged cluster IDs
        group_to_cluster_ids = defaultdict(list)
        for i, cluster_id in enumerate(sorted_ids):
            group_id = find(i)
            group_to_cluster_ids[group_id].append(cluster_id)

        # Merge clusters into new map
        merged_cluster_map = {}
        new_cluster_id = 0
        for cluster_ids in group_to_cluster_ids.values():
            merged_files = []
            for cid in cluster_ids:
                merged_files.extend(cluster_map.get(cid, []))
            merged_cluster_map[new_cluster_id] = merged_files
            new_cluster_id += 1

        return merged_cluster_map